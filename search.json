[
  {
    "objectID": "reproducibility/patient_stratification.html",
    "href": "reproducibility/patient_stratification.html",
    "title": "Patient stratification",
    "section": "",
    "text": "The list of packages required for reproducing the analyses on this script are listed in Listing 1. Besides, the downloadable R script file utils stores two helper functions:\nListing 1: Packages required for analysing biological differences between patient conditions.\n\n\n\nCode\nlibrary(CoRC)\n\n# Data wrangling\nlibrary(dplyr)\nlibrary(readr)\n\n# Table visualisation\nlibrary(scales)\nlibrary(flextable)\n\n# Plot visualisation\nlibrary(ggplot2)\nlibrary(latex2exp)\nlibrary(cowplot)\n\nsource(\"../../scripts/utils.R\")",
    "crumbs": [
      "Patient Stratification"
    ]
  },
  {
    "objectID": "reproducibility/patient_stratification.html#parameter-estimation-and-patient-stratification",
    "href": "reproducibility/patient_stratification.html#parameter-estimation-and-patient-stratification",
    "title": "Patient stratification",
    "section": "1 Parameter estimation and patient stratification",
    "text": "1 Parameter estimation and patient stratification\nTo run an experimental design, we need:\n\nthe model itself, and notably the steady-state concentrations, and the parameter constants.\nExperimental data, where for a given condition (here, patient cluster), the columns correspond to the species concentrations, and the rows to the indiviudal observations. Real-life measures of fold changes have been reported in Table 1.\nThe R code used for loading the healthy model and the clinical datasets, is reported in Listing 21.\n\n\n1.1 Differential analyses\nNote that Lo et al. (2016) did not provide unfortunately the individual cytokine concentrations, preventing from reproducing the differential analyses and quite hampering the validity of Parameter estimation Task.\n\n\n\n\nListing 2: Code snippet not run, used for illustration example.\n\n\n\nCode\n# Load Healthy ODE model along with the parameter constants\nhealthy_model &lt;- loadModel(\"../../models/team_2016_final_model_lo2016_2025_05_13.cps\")\nhealthy_steaty_state &lt;- runSteadyState(\n  calculate_jacobian = FALSE,\n  model = healthy_model\n)$species |&gt;\n  dplyr::select(name, concentrationH = concentration)\n\n# Load experimental datasets providing real-life concentrations of cytokines\ncluster_type &lt;- c(\"Type 1\", \"Type 2\", \"Type 3\", \"Type 4\")\ndata_experiment &lt;- readr::read_csv(\"../../data/IBD DGEA.csv\", show_col_types = FALSE) |&gt;\n  tidyr::pivot_longer(!cluster, names_to = \"name\", values_to = \"concentration\") |&gt;\n  dplyr::left_join(healthy_steaty_state, by = \"name\") |&gt;\n  mutate(\n    concentration = if_else(!is.na(concentrationH),\n                            concentrationH * (1 + concentration / 100), concentration\n    ),\n    concentrationH = NULL\n  ) |&gt;\n  tidyr::pivot_wider(names_from = name, values_from = concentration) |&gt;\n  split(f = cluster_type)\n\n\n\n\n\n\n\n\n\n\nTypes of diseaseSpeciesSpecies' concentration at steady-stateConcentrations in IBD clustersfold changetype 1I61.46e-061.02e-07-93.0%type 1I103.01e-081.48e-08-51.0%type 1Ia2.72e-051.88e-05-31.0%type 1Ib*1.64e-137.23e-14-56.0%type 1Ig*2.01e-072.01e-09-99.0%type 2I61.46e-063.78e-07-74.0%type 2I103.01e-082.56e-08-15.0%type 2Ia2.72e-051.88e-05-31.0%type 2Ib*1.64e-131.54e-13-6.0%type 2Ig*2.01e-071.61e-08-92.0%type 3I61.46e-061.96e-0635.0%type 3I103.01e-084.34e-0844.0%type 3Ia2.72e-054.00e-0547.0%type 3Ib*1.64e-131.95e-1319.0%type 3Ig*2.01e-071.17e-06481.0%type 4I61.46e-062.47e-07-83.0%type 4I103.01e-081.99e-08-34.0%type 4Ia2.72e-051.49e-05-45.0%type 4Ib*1.64e-131.31e-13-20.0%type 4Ig*2.01e-071.00e-08-95.0%*These quantities have not been measured, but rather estimated from the model.\n\n\n\nTable 1: Fold changes of cytokine concentrations obtained from clinical data, reported in Table 7, (Lo et al. 2016, 13). Species is the cytokines’ name, while cluster indicator is returned by Types of disease. Note that we have not reported species concentrations of \\(T-Bet\\), \\(Gata3\\), \\(ROR \\gamma t\\), and \\(Foxp3\\) as not measured in the ODE model.\n\n\n\n\n\n\n1.2 Configure the experimental design and the numerical optimisations\n\n\nCode\n# define larger lower and upper bounds\nfree_parameters_key &lt;- getParameters(c(\n  \"(Prod of Ig from T1).k1\",\n  \"(Prod of Ia from T1).k1\",\n  \"(Prod of Ib from Tr).k1\",\n  \"(Prod of I10 from Tr).v10r\",\n  \"(Induction of T1 from M).s12\",\n  \"(Induction of T2).s4\",\n  \"(Induction of T17).s21\",\n  \"(Induction of T17).s6\",\n  \"(Induction of Tr).sb\",\n  \"(Induction of Tr).s10\"\n), model = healthy_model)$key\n\n\nfit_parameters &lt;- purrr::map(free_parameters_key, function(param) {\n  val &lt;- getParameters(param)$value\n  defineParameterEstimationParameter(\n    ref = parameter(param, \"Value\"),\n    start_value = val,\n    lower_bound = 1e-15,\n    upper_bound = 1e4\n  )\n})\n\nmapping_present &lt;- getSpeciesReferences(\n  key = c(\"I6\", \"I10\", \"Ia\", \"Ib\", \"Ig\"),\n  model = healthy_model\n) |&gt; pull(concentration)\n\nfit_experiments &lt;- purrr::map(data_experiment, ~ defineExperiments(\n  experiment_type = \"steady_state\",\n  data = .x,\n  types = c(\n    \"ignore\", \"dependent\", \"dependent\", \"dependent\",\n    \"ignore\", \"ignore\", \"ignore\", \"ignore\", \"ignore\", \"ignore\"\n  ),\n  mappings = c(NA, mapping_present,  rep(NA, 4)),\n  weight_method = \"mean_square\"\n))\n\n\n1free_parameters_key &lt;- getParameters(c(\"(Prod of Ig from T1).k1\",\n                                       \"(Prod of Ia from T1).k1\",\n                                       \"(Prod of Ib from Tr).k1\",\n                                       \"(Prod of I10 from Tr).v10r\",\n                                       \"(Induction of T1 from M).s12\",\n                                       \"(Induction of T2).s4\",\n                                       \"(Induction of T17).s21\",\n                                       \"(Induction of T17).s6\",\n                                       \"(Induction of Tr).sb\",\n                                       \"(Induction of Tr).s10\"), model = healthy_model)$key\n\n2fit_parameters &lt;- purrr::map(free_parameters_key, function(param) {\n  val &lt;- getParameters(param)$value\n  defineParameterEstimationParameter(\n    ref = parameter(param, \"Value\"),\n    start_value = val,\n    lower_bound = 1e-15,\n    upper_bound = 1e4)\n})\n\nmapping_present &lt;- getSpeciesReferences(\n  key = c(\"I6\", \"I10\", \"Ia\", \"Ib\", \"Ig\"),\n  model = healthy_model\n) |&gt; pull(concentration)\n\n3fit_experiments &lt;- purrr::map(data_experiment, ~ defineExperiments(\n  experiment_type = \"steady_state\",\n  data = .x,\n  types = c(\n    \"ignore\", \"dependent\", \"dependent\", \"dependent\",\n    \"ignore\", \"ignore\", \"ignore\", \"ignore\", \"ignore\", \"ignore\"),\n4  mappings = c(NA, mapping_present,  rep(NA, 4)),\n5  weight_method = \"mean_square\"\n))\n\n1\n\nTo adjust the variations of steady-state concentrations observed in the identified four subgroups of patients suffering from Inflammatory Bowel Disease, Lo et al. (2016) chose to play with 10 biological constants (10 degrees of freedom). Note that for the system of equations to be determined (at the very least), the number of free parameters to estimate must be equal or inferior to the number of equations (here, one by species included in the ODE model, aka 15).\n\n2\n\nWe initialise the iterative search by initialising the 10 free parameters with the biological constant vitals observed in healthy individuals. Besides, we can enforce bounds (either for each of the parameters, or shared by all of them), coercing the optimisation algorithm not to go beyond.\n\n3\n\nFor each of the patient subgroups, we need to provide the type of experiment (either steady-state, or time_course when several time points have been considered in the design), the measured concentrations diverging from the average concentrations in healthy patients with data, define each of the measured variables (constant with independent, dependent if used for tailoring the parameter estimates, or ignore if not quantified in the ODE model). We had only the averaged expression per patient subgroup To better capture within-patient variability, it would have been valuable to provide the individual cytokine profiles, and perform a multiple least-squares regression, aka MMR task.\n\n4\n\nmappings guarantees the proper pairing between COPASI variables and string values of column names2.\n\n5\n\nFinally, the [weight_method] coupled with weights describe for each variable the assumed mean-variation trend. Report to COPASI Manual, section Experimental Data, for further details.\n\n\nFinally, once the experimental design and optimisation criteria have been configured independently for each free parameter and patient subgroup, we have to run the parameter estimation itself:\n\n\nCode\nabsolute_parameter_per_cluster &lt;- purrr::map(fit_experiments, function(cluster) {\n  # CoRC update imposes to restart from a clean model for parameter estimation\n  CoRC::clearParameterEstimationParameters(model = healthy_model)\n  CoRC::clearExperiments(model = healthy_model)\n  \n  return(runParameterEstimation(\n    parameters = fit_parameters,\n    experiments = cluster,\n    method = list(\n      method = \"LevenbergMarquardt\",\n      log_verbosity = 0, \n      iteration_limit = 200,\n      tolerance = 1e-5\n    ),\n    update_model = FALSE, \n    randomize_start_values = FALSE,\n    create_parameter_sets = TRUE,\n    calculate_statistics = FALSE,\n    model = healthy_model\n  )$parameters)\n})\n\n# Make results directly comparable with Table 8 by switching from absolute to relative ratios\nrelative_parameter_per_cluster &lt;- absolute_parameter_per_cluster |&gt; \n  purrr::list_rbind(names_to = \"cluster\") |&gt; \n  dplyr::select(cluster, parameter, start_value, value) |&gt; \n  mutate (relative_concentration = 100*(value - start_value)/start_value,\n          start_value = NULL, value = NULL) |&gt; \n  tidyr::pivot_wider(names_from = parameter, values_from = relative_concentration) \n\n\n1absolute_parameter_per_cluster &lt;- purrr::map(fit_experiments, function(cluster) {\n2  CoRC::clearParameterEstimationParameters(model = healthy_model)\n  CoRC::clearExperiments(model = healthy_model)\n3  return(runParameterEstimation(\n    parameters = fit_parameters,\n    experiments = cluster,\n4    method = list(method = \"LevenbergMarquardt\",\n                  iteration_limit = 500,\n                  tolerance = 1e-6),\n    update_model = FALSE,\n    randomize_start_values = FALSE,\n    create_parameter_sets = TRUE,\n    calculate_statistics = FALSE,\n    model = healthy_model\n  )$parameters)\n})\n\n1\n\nWe learn a configuration of 10 free parameters independently for each patient subgroup.\n\n2\n\nRecall that in COPASI, models are modified by reference rather than by copy. These auxiliary functions, clearParameterEstimationParameters and clearExperiments guarantee a fresh start for parameter estimation for each scenario.\n\n3\n\nThe core function, runParameterEstimation, of the pipeline for estimating varying constants across distinct biological conditions.\n\n4\n\nThere are plenty of optimisation approaches to reduce the discrepancy between the healthy-state concentrations of immune cells, and the ones observed across each patient cluster, listed in Optimization Methods. Unfortunately, the precise optimisation method used in Lo et al. (2016) has not been detailed, nor the hyperparameters used. We arbitrarily chose the Levenberg - Marquardt approach that is a good compromise between first-order, steepest descent approaches, and second-order, Newton-Raphson like approaches (see Tip 1 for details). The iteration_limit determines the maximum number of iterations the algorithm shall perform, while tolerance is the numerical precision to reach between two consecutive iterations.\n\n\n\n\n\n\n\n\nTip 1: Optimisation Descent Methods\n\n\n\n\n\nConsider a multivariate function \\(f(\\mathbf{x})\\) that we want to maximize with respect to \\(\\mathbf{x}\\) (for instance, we may want to minimise the mean-squared error between estimated steady-state concentrations and ones measured in each patient subgroup). Standard unconstrained optimization approaches include Gradient Descent (see Equation 1), Newton-Raphson (see Equation 2) and Levenbergh-Marquart (see Equation 3):\n\nThe Steepest Descent Approach, where the method updates \\(\\mathbf{x}\\) in the direction of the gradient (steepest slope):\n\\[\n\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\nabla f(\\mathbf{x}_k)\n\\tag{1}\\]\nwhere:\n\n\\(\\nabla f(\\mathbf{x}_k)\\) is the gradient of \\(f\\) at \\(\\mathbf{x}_k\\),\n\n\\(\\alpha_k\\) is the step size (learning rate), sometimes fixed. Playing on this parameter may prevent revolving round the optimum.\n\nThe steepest descent method only converges linearly, but is guaranteed to converge.\n\n\nThe Newton-Raphson Approach is a second-order method, requiring the computation of the Hessian matrix:\n\\[\n\\mathbf{x}_{k+1} = \\mathbf{x}_k +  \\mathbf{H}^{-1}(\\mathbf{x}_k) \\nabla f(\\mathbf{x}_k)\n\\tag{2}\\]\nwhere:\n\n\\(\\mathbf{H}(\\mathbf{x}_k) = \\nabla^2 f(\\mathbf{x}_k)\\) is the Hessian matrix,\n\n\\(\\nabla f(\\mathbf{x}_k)\\) is the gradient.\n\nOn the other hand, the Newton method converges quadratically towards the minimum in its vicinity. However, it’s really sensible to the initialisation, and may not converge at all if it is far away from it.\n\nThe Levenberg-Marquardt Descent Approach (Equation 3):\n\\[\n\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\left( \\mathbf{H}(\\mathbf{x}_k) + \\lambda \\mathbf{I} \\right)^{-1} \\nabla f(\\mathbf{x}_k)\n\\tag{3}\\]\nwhere \\(\\lambda\\) is a dampening hyper-parameter controlling the trade-off between gradient descent, when \\(\\lambda \\to \\infty\\), and Newton’s method \\(\\lambda \\to 0\\).\n\n\n\n\n\n1.3 Reporting of parameter estimations\nOur estimations are compared with Table 8, (Lo et al. 2016, 13) variations in Table 2.\nOf note, all tables in the original paper were provided as screenshots and images, rather than CSV files, preventing straightforward reproducibility of the results.\n\n\nCode\n# flextable formatting and variables\nvariable_labels &lt;- list(\n  cluster = \"Type of diseases\",\n  `(Prod of Ig from T1).k1` = \"coefficient of IFN-gamma by Th1\", \n  `(Prod of Ia from T1).k1` = \"coefficient of TNF-alpha by Th1\", \n  `(Prod of Ib from Tr).k1` = \"coefficient of TGF-beta by Treg\",\n  `(Prod of I10 from Tr).v10r` = \"coefficient of IL-10 by Treg\",\n  `(Induction of T1 from M).s12` = \"activation of Th1 cells\", \n  `(Induction of T2).s4` = \"activation of Th2 cells\", \n  `(Induction of T17).s21` = \"activation of Th17 cells\",\n  `(Induction of T17).s6` = \"activation of Th17 cells\", \n  `(Induction of Tr).sb` = \"activation of Treg cells\",\n  `(Induction of Tr).s10` = \"activation of Treg cells\"\n)\nheader_row &lt;- c(\n  \"\\\\text{Type of diseases}\",\n  \"\\\\nu_{\\\\gamma_1}\",\n  \"\\\\nu_{\\\\alpha_1}\", \n  \"\\\\nu_{\\\\beta_{\\\\rho}}\",\n  \"\\\\nu_{10_{\\\\rho}}\",\n  \"\\\\sigma_{12}\",\n  \"\\\\sigma_{4}\",\n  \"\\\\sigma_{21}\",\n  \"\\\\sigma_{6}\",\n  \"\\\\sigma_{\\\\beta}\",\n  \"\\\\sigma_{10}\") |&gt; \n  as_equation() |&gt;\n  as_paragraph()\n\n# flextable generation\n\nrelative_parameter_variations_flextable &lt;- flextable(relative_parameter_per_cluster) |&gt; \n  # Add gradient colouring based on values\n  bg(\n    j = setdiff(names(variable_labels), \"cluster\"), \n    bg = colourer) |&gt; \n  # Format numbers (optional for consistent display)\n  colformat_double(j = setdiff(names(variable_labels), \"cluster\"),\n                   suffix = \"%\",\n                   big.mark = \",\", \n                   digits = 1) |&gt; \n  append_chunks(j = \"cluster\",\n                # what to append\n                as_equation(c(\"\\\\text{Th1}\\\\uparrow \\\\text{Th2}\\\\downarrow\",\n                              \"\\\\text{Th1}\\\\downarrow \\\\text{Th2}\\\\uparrow\", \n                              \"\\\\text{Th1}\\\\uparrow \\\\text{Th2}\\\\uparrow\",\n                              \"\\\\text{Th1}\\\\downarrow \\\\text{Th2}\\\\downarrow\"))\n  ) |&gt; \n  # Rename columns using LaTeX-like notation\n  set_header_labels(values = variable_labels\n  ) |&gt; \n  add_header_row(values = header_row,\n                 colwidths = rep(1, 11), top = FALSE\n  ) |&gt; \n  align(align = \"center\", part = \"all\") |&gt; \n  set_caption(\"Table 8: Parameter variations in different types of diseases. \n              In blue, disease subtype induces shrinkage of the coefficients, \n              while red values correspond to increased parameter uptakes. \") |&gt;\n  merge_at(part = \"head\", i = 1:2, j = 1)\nrelative_parameter_variations_flextable\n\n\n\n\n\nType of diseasescoefficient of IFN-gamma by Th1coefficient of TNF-alpha by Th1coefficient of TGF-beta by Tregcoefficient of IL-10 by Tregactivation of Th1 cellsactivation of Th2 cellsactivation of Th17 cellsactivation of Th17 cellsactivation of Treg cellsactivation of Treg cellsNANANANANANANANANANAType 1NA25.0%-2.6%-48.9%120.8%-2.0%15.8%-100.0%-100.0%269.4%332.6%Type 2NA-3.5%-2.7%-86.7%195.2%-2.1%16.2%-100.0%-100.0%264.9%327.1%Type 3NA792,307.4%19.5%-100.0%-100.0%5.5%-55.2%-100.0%6,303.3%734.3%734.7%Type 4NA96,781.1%-4.1%5,510,497,212,108.6%-100.0%-3.1%24.1%-100.0%-96.9%378.7%467.5%\n\n\n\nTable 2: Estimation of parameter variations in different patient subgroups, reported in Table 8, (Lo et al. 2016, 13)3.\n\n\n\n\nOne of the major advantages of flextable lies in its ability to save the generated flextable object in a variety of formats, including docx, and html, as illustrated in Listing 3 (or even several ones simultaneously).\n\n\n\n\nListing 3: Flextable multiple outputs.\n\n\n\nCode\nsave_as_html(relative_parameter_variations_flextable,\n  path = \"../../results/Table8.html\",\n  title = \"Table 8: Parameter variations per disease subtype.\"\n)\n\nsave_as_docx(relative_parameter_variations_flextable,\n  path = \"../../results/Table8.docx\",\n  title = \"Table 8: Parameter variations per disease subtype.\"\n)",
    "crumbs": [
      "Patient Stratification"
    ]
  },
  {
    "objectID": "reproducibility/patient_stratification.html#treatment-outcome-and-patient-stratification",
    "href": "reproducibility/patient_stratification.html#treatment-outcome-and-patient-stratification",
    "title": "Patient stratification",
    "section": "2 Treatment outcome and patient stratification",
    "text": "2 Treatment outcome and patient stratification\nThe objective of this section is to predict the efficiency of a novel anti-TNF-\\(\\alpha\\) treatment, assuming that the blocking treatment is equivalent to force the concentration of TNF-\\(\\alpha\\) to remain zero, and calculate the change of other variables at the steady-state concentrations.\nSecond objective is to determine the efficiency of the treatment conditioned to the patient endotype determined using patient stratification approaches.\n\n2.1 Load Free Parameter variations in different types of diseases\nSince the results of parameter estimation reported in Section 1.3 differ significantly from the results reported in the original paper, Table 8, Lo et al. (2016), pp. 13, we directly retrieve in that section the original estimates from Lo et al. (2016).\n\n\nCode\n## Prepare parameter variations for each of the four patient subtypes ----\nhealthy_model &lt;- suppressWarnings(loadModel(\"../../models/team_2016_final_model_lo2016_2025_05_13.cps\"))\n\n# retrieve parameter mapping\nparameters_per_clusters &lt;- getParameters(c(\"(Prod of Ig from T1).k1\",\n                          \"(Prod of Ia from T1).k1\",\n                          \"(Prod of Ib from Tr).k1\",\n                          \"(Prod of I10 from Tr).v10r\",\n                          \"(Induction of T1 from M).s12\",\n                          \"(Induction of T2).s4\",\n                          \"(Induction of T17).s21\",\n                          \"(Induction of T17).s6\",\n                          \"(Induction of Tr).sb\",\n                          \"(Induction of Tr).s10\"), model = healthy_model)\n\n# retrieve parameter variations specific to each disease subtype ...\npatient_group &lt;- c(\"Type1\", \"Type2\", \"Type3\", \"Type4\")\nparameters_per_clusters &lt;- parameters_per_clusters |&gt; \n  dplyr::inner_join(readr::read_csv(\"../../data/IBD subgroups.csv\", show_col_types = FALSE), by = \"key\") |&gt; \n  rename(healthy = value) |&gt; \n  dplyr::select(-mapping) |&gt; \n  # ... and convert relative ratios to absolute\n  dplyr::mutate(across(all_of(patient_group), \\(x) healthy *  (1 + x/100)))\n\n# run healthy steady state\nhealthy_steaty_state &lt;- runSteadyState(\n  calculate_jacobian = FALSE,\n  model = healthy_model)$species |&gt; \n  dplyr::select(name, concentrationH = concentration) |&gt; \n  filter (name %in% c(\"I6\", \"I10\", \"Ia\", \"T1\", \"T2\",\"T17\", \"Tr\", \"Ig\", \"Ib\"))\n\n\n\n\n2.2 Model the effect of TNF-alpha blockade\nsteady_states_per_cluster &lt;- purrr::map(patient_group, function(cluster) {\n  # without anti-TNF alpha treatment\n1  disease_model_without_treatment &lt;- healthy_model |&gt; saveModelToString() |&gt;  loadModelFromString()\n  setParameters(model = disease_model_without_treatment,\n                key = parameters_per_clusters$key,\n                value = parameters_per_clusters[[cluster]])\n  without_treatment_steady_state &lt;- runSteadyState(\n    calculate_jacobian = FALSE,\n    model = disease_model_without_treatment)$species |&gt;\n    dplyr::select(name, concentration) |&gt;\n    inner_join(healthy_steaty_state, by = \"name\") |&gt;\n    mutate (concentration = 100* (concentration - concentrationH) / concentrationH) |&gt;\n    dplyr::select(-concentrationH) |&gt;\n    mutate(cluster = cluster, category = \"untreated\")\n    \n  # with anti-TNF alpha treatment\n  disease_model_with_treatment &lt;- suppressWarnings(disease_model_without_treatment |&gt; \n                                                     saveModelToString() |&gt;  \n                                                     loadModelFromString())\n2  setSpecies(key = \"Ia{compartment}\",\n             initial_concentration = 0,\n             type =\"fixed\",\n             model = disease_model_with_treatment)\n3  with_treatment_steady_state &lt;- runSteadyState(\n    calculate_jacobian = FALSE,\n    model = disease_model_with_treatment)$species |&gt;\n    dplyr::select(name, concentration) |&gt;\n    inner_join(healthy_steaty_state, by = \"name\") |&gt;\n    mutate (concentration = 100* (concentration - concentrationH) / concentrationH) |&gt;\n    dplyr::select(-concentrationH) |&gt;\n    tibble::add_row(name = \"Ia\", concentration = 0) |&gt;\n    mutate(cluster = cluster, category = \"treated\")\n    \n  return (rbind(without_treatment_steady_state, with_treatment_steady_state))\n  \n4}) |&gt; dplyr::bind_rows()\n\n1\n\nEstimate steady-state conditions for each of the four patient subgroups identified, without anti-TNF-\\(\\alpha\\) treatment.\n\n2\n\nConstrain TNF-\\(\\alpha\\) to remain fixed and null by setting the initial concentration level to \\(0\\). Both parameters are required to ensure absence of TNF-\\(\\alpha\\).\n\n3\n\nPredict the new steady-state conditions after therapeutic treatment.\n\n4\n\ndplyr::bind_rows() merges a list of data.frame into a single one.\n\n\n\n\n2.3 Simulation visualisations of the fold changes of the cytokine and T cell concentrations\nWe have reproduced Fig.3 from Lo et al. (2016), pp. 13, in Figure 1, using a combination of ggplot2for individual barplot representations and cowplot for individual ‘ggplot’ concatenations.\n\n\nCode\n\n# Reproduce boxplots of Figure 3, pre and post-treatment ----\n# Format dataset for plotting\nsteady_states_per_cluster_plot &lt;- steady_states_per_cluster |&gt; \n  mutate (name = factor (name, \n                         levels = c(\"I6\", \"I10\", \"Ia\",  \"T1\", \"T2\",\n                                    \"T17\", \"Tr\", \"Ig\", \"Ib\"),\n                         labels = c(\"IL-6\", \"IL-10\", \"TNF-alpha\", \"Th1\", \"Th2\", \n                                    \"Th17\", \"Treg\", \"IFN-gamma\", \"TFG-beta\"), \n                         ordered = TRUE),\n          category  = factor(category, \n                           levels = c(\"untreated\", \"treated\"), ordered = TRUE))\n\ncluster_labels &lt;- c(\"Type 1: Th1\\\\uparrow Th2\\\\downarrow\",\n                    \"Type 2: Th1\\\\downarrow Th2\\\\uparrow\", \n                    \"Type 3: Th1\\\\uparrow Th2\\\\uparrow\",\n                    \"Type 4: Th1\\\\downarrow Th2\\\\downarrow\") \nnames(cluster_labels) &lt;- c(\"Type1\", \"Type2\", \"Type3\", \"Type4\")\n\n\n### Retrieve legend ----\nglobal_plot &lt;- ggplot(data = steady_states_per_cluster_plot, \n                      mapping = aes(x = name, y = concentration, fill = category)) +\n  geom_col(position = \"dodge\") +\n  scale_fill_manual(name =\"Treatment\", values=c(\"blue\", \"red\")) + \n  guides(color = guide_legend(nrow = 1)) +\n  theme(legend.position = \"bottom\") \n\n### Generate bar plot for each disease subtype ----\nlist_plots &lt;- purrr::imap(cluster_labels, ~ ggplot(data = steady_states_per_cluster_plot |&gt; filter(cluster==.y), \n                                                   mapping = aes(x = name, y = concentration, fill = category)) +\n                            geom_col(position = \"dodge\")+\n                            labs(x = NULL, y = NULL) +\n                            scale_fill_manual(name =\"Treatment\", values=c(\"blue\", \"red\")) +\n                            theme_minimal() +\n                            theme(panel.grid.major = element_blank(),\n                                  legend.position = \"none\", plot.title = element_text(hjust = 0.5)) +\n                            ggtitle(TeX(.x)))\n\n### Combine barplots into a 2x2 grid ----\nplot_grid_combined &lt;- cowplot::plot_grid(plotlist = list_plots, \n  ncol = 2, align = \"hv\", axis = \"tblr\") \n\nx_label &lt;- ggdraw() + draw_label(\"Cell Species\", x = 0.5, y = 0.5)\ny_label &lt;- ggdraw() + draw_label(\"ODE Parameters\", x = 0.5, y = 0.5, angle = 90)\n\n# Add global y label\nplot_grid_combined &lt;- cowplot::plot_grid(y_label,\n  plot_grid_combined,\n  nrow = 1,\n  rel_widths = c(0.1, 1)  # Adjust width for the legend\n)\n\nlegend_plot &lt;- get_legend_temp(global_plot)\n\n# Add global x label\nplot_grid_combined &lt;- cowplot::plot_grid(plot_grid_combined, \n                   x_label,\n                   legend_plot,\n                   nrow = 2, ncol =1,\n                   rel_heights = c(1, 0.1)  # Adjust width for the legend\n)\n\nplot_grid_combined &lt;- cowplot::plot_grid(\n  plot_grid_combined,\n  legend_plot,\n  nrow = 2,\n  rel_heights = c(1, 0.1)  # Adjust width for the legend\n)\n\nplot_grid_combined\n\n\n\n\n\n\n\n\nFigure 1: Simulation results of the fold changes of the cytokine and T-cell concentrations when TNF-\\(\\alpha\\) is completely blocked in the four group of identified patients. Blue bars represent the results of pre-treatment; red bars represent the results of post-treatment with TNF-\\(\\alpha\\) blockage. Reproduction of (Lo et al. 2016, 13), Fig.3.",
    "crumbs": [
      "Patient Stratification"
    ]
  },
  {
    "objectID": "reproducibility/patient_stratification.html#footnotes",
    "href": "reproducibility/patient_stratification.html#footnotes",
    "title": "Patient stratification",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nnote the final split() instruction: indeed, the expected input is a list of experiences, each element of the list matching a subgroup of patients with their own set of free parameters↩︎\nIn contrast with documentation, this step seems mandatory, as the output returned by `` has a placeholder typical syntax.↩︎\nWebshot table↩︎",
    "crumbs": [
      "Patient Stratification"
    ]
  },
  {
    "objectID": "reproducibility/steady_state.html",
    "href": "reproducibility/steady_state.html",
    "title": "Steady-state computations",
    "section": "",
    "text": "The list of packages required for reproducing the analyses on this script are listed in Listing 1:\nListing 1: Packages required for computing and displaying steady-state conditions.\n\n\n\nCode\n# install and load R connector to COPASI software\n# remotes::install_github(\"jpahle/CoRC\")\nlibrary(CoRC)\nlibrary(testthat)\n\n# tidyverse packages\nlibrary(dplyr)\n\n# Table reporting\nlibrary(flextable)",
    "crumbs": [
      "Steady State"
    ]
  },
  {
    "objectID": "reproducibility/steady_state.html#run-steady-state-analyses",
    "href": "reproducibility/steady_state.html#run-steady-state-analyses",
    "title": "Steady-state computations",
    "section": "1 Run steady-state Analyses",
    "text": "1 Run steady-state Analyses\nThe call to CoRC::runSteadyState() function retrieves the steady-state of the ODE model (see Note 1 for the mathematical definition of steady states).\n1healthy_model &lt;- loadModel(\"../../models/team_2016_final_model_lo2016_2025_05_13.cps\")\n2healthy_model_steady_state &lt;- runSteadyState(\n  model = healthy_model,\n  calculate_jacobian = TRUE,\n  perform_stability_analysis = TRUE,\n3  method = list(\"use_newton\"=TRUE, accept_negative_concentrations = FALSE)\n)\n\n1\n\nRun CoRC::loadModel() function to load the COPASI model in R.\n\n2\n\nWe use the CoRC::runSteadyState function to run the steady-states…\n\n3\n\n… and for this task, several algorithms can be chosen, when no explicit solution can be derived directly. We used in our framework the well-known root-finding Newton-Raphson algorithm.\n\n\n\n\n\n\n\n\nNote 1: Derive Steady-States Conditions of an ODE model\n\n\n\nComputing the steady-state conditions for an ordinary differential equation (ODE) means finding the system’s equilibrium points, where the variables (also named the species) remain constant over time. In other words, this means finding the concentrations for which all the derivatives cancel:\nGiven a system of \\(n=15\\) ODEs (number of varying species in the simulated model),\n\\[\n\\begin{cases}\n\\frac{dx_1}{dt} &= f_1(x_1, x_2, \\dots, x_{15}) \\\\\n\\frac{dx_2}{dt} &= f_2(x_1, x_2, \\dots, x_{15}) \\\\\n&\\vdots \\\\\n\\frac{dx_{15}}{dt} &= f_n(x_1, x_2, \\dots, x_{15})\n\\end{cases}\n\\]\nthe steady-state conditions are obtained by solving system Equation 1:\n\\[\n\\begin{cases}\nf_1(x_1^*, x_2^*, \\dots, x_{15}^*)& = 0 \\\\\nf_2(x_1^*, x_2^*, \\dots, x_{15}^*) &= 0 \\\\\n& \\vdots \\\\\nf_n(x_1^*, x_2^*, \\dots, x_{15}^*) &= 0.\n\\end{cases}\n\\tag{1}\\]\n\n\nTo ensure that the model converged, we assert in Listing 2 that the outcome of the stability analysis is found. Other outcomes include notFound and foundNegative (which is unrealistic in our setting, since concentrations of species can either be positive or null).\n\n\n\n\nListing 2: Check that the model converged with a testthat equal. If not, returns an error.\n\n\n\nCode\ntestthat::expect_equal(healthy_model_steady_state$result, \"found\")",
    "crumbs": [
      "Steady State"
    ]
  },
  {
    "objectID": "reproducibility/steady_state.html#report-steady-state-analyses",
    "href": "reproducibility/steady_state.html#report-steady-state-analyses",
    "title": "Steady-state computations",
    "section": "2 Report steady-state analyses",
    "text": "2 Report steady-state analyses\nIn Table 1, we report the concentrations of the 15 varying species included in the Lo et al. (2016) ODE model describing the dynamic relations among pools of immune cells (macrophages and T-cells) and the secreted cytokines, using the flextable package (Gohel and Skintzos 2024).\n\n\nCode\n## Format table for reporting.\nsteady_state_concentrations &lt;- healthy_model_steady_state$species |&gt; \n  select(name, concentration) |&gt; \n  mutate(name = factor(name, \n                          levels = c(\"M1\", \"M2\", \n                                     \"T1\", \"T2\",\n                                     \"T17\", \"Tr\",\n                                     \"Ig\", \"I2\", \"I4\", \"I21\", \"I6\",\n                                     \"Ia\", \"I10\", \"Ib\", \"I12\"),\n                          labels = c(\"M1 macrophage\", \"M2 macrophage\", \n                                     \"Th1 cell\", \"Th2 cell\",\n                                     \"Th17 cell\", \"Treg cell\", \n                                     \"IFN-g\", \"IL-2\", \"IL-4\", \"IL-21\", \"IL-6\", \n                                     \"TNF-a\", \"IL-10\", \"TFG-b\", \"IL-12\"),\n                       ordered = TRUE)) |&gt; \n  arrange(name)\n\n## Format steady-state analysis report for Table 4 ----\nsteady_state_labels &lt;- list(\n  name = \"Species\",\n  concentration = \"Value(g/cm^3)\")\n\nsteady_state_table &lt;- flextable(steady_state_concentrations) |&gt; \n  # format to scientific notation, allowing max 2 significant digits\n  colformat_double(j = \"concentration\", digits = 3) |&gt; \n  set_formatter(concentration = function(x) {\n    formatC(x, format = \"e\", digits = 2)\n  }) |&gt; \n  add_footer_row(values = \"doi:10.1371/journal.pone.0165782.t004\", \n                 colwidths = 2) |&gt; \n  compose(j = \"name\", \n          i = ~ name %in% c(\"IFN-g\", \"TNF-a\", \"TFG-b\"),\n          value = as_paragraph(as_equation(c(\"\\\\text{IFN}_{\\\\gamma}\",\n                                             \"\\\\text{TNF}_{\\\\alpha}\",\n                                             \"\\\\text{TGF}_{\\\\beta}\")))) |&gt; \n  set_header_labels(values = steady_state_labels) |&gt; \n  bold(part = \"header\") |&gt; \n  set_caption(\"Table 4: Steady-state concentrations of cytokines,\n              macrophages and T cells in a healthy individual.\") \n\nsteady_state_table\n\n\n\n\n\nSpeciesValue(g/cm^3)M1 macrophage1.17e-02M2 macrophage8.17e-03Th1 cell1.40e-01Th2 cell3.99e-03Th17 cell6.18e-03Treg cell2.98e-04NA2.01e-07IL-21.07e-08IL-43.36e-09IL-217.77e-08IL-61.46e-06NA2.72e-05IL-103.01e-08NA1.64e-13IL-123.64e-07doi:10.1371/journal.pone.0165782.t004\n\n\n\nTable 1: Steady-state concentrations of cytokines, macrophages and T cells in healthy individuals, see also Table 4 reported in (Lo et al. 2016, 10).",
    "crumbs": [
      "Steady State"
    ]
  },
  {
    "objectID": "files.html",
    "href": "files.html",
    "title": "Files",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Overview",
    "section": "",
    "text": "This is a Quarto book project: you can download a Web, HTML and pdf version."
  },
  {
    "objectID": "index.html#original-paper",
    "href": "index.html#original-paper",
    "title": "Overview",
    "section": "1 Original paper",
    "text": "1 Original paper\nThe original pdf source of Lo et al. (2016) is embedded in Figure 1.\n\n\n\nDownload PDF file.\n\n\nFigure 1"
  },
  {
    "objectID": "index.html#ode-model-and-network",
    "href": "index.html#ode-model-and-network",
    "title": "Overview",
    "section": "2 ODE model and network",
    "text": "2 ODE model and network\nWe report in Figure 2 the biological network model underlying the intertwined interactions between immune cell subtypes (T-cells and Macrophaes) and realeased cytokines.\n\n\n\n\n\n\nFigure 2: Bi-Directed diagram describing the interactions between immune cells in the inflammatory bowel disease IBD, from Lo et al. (2016), pp. 3"
  },
  {
    "objectID": "index.html#reproducibility",
    "href": "index.html#reproducibility",
    "title": "Overview",
    "section": "3 Reproducibility",
    "text": "3 Reproducibility\nThe list of packages required for reproducing the tutorials are listed in Table 1:\n\n##  Finding R package dependencies ... Done!\n\n\n\n\nSourcePackagepatient_stratificationCoRCcowplotdplyrflextableggplot2latex2expreadrscalestidyrpurrrtibbleprccCoRCdplyrflextableggplot2lhsparallelppcortibblereadrtidyrsteady_stateCoRCdplyrflextabletestthat2-IBD-simulationsCoRCdplyrflextabletidyrreadr\n\n\n\nTable 1: List of dependencies, per file."
  },
  {
    "objectID": "GTBioSS_slides.html",
    "href": "GTBioSS_slides.html",
    "title": "GT Bioss presentation",
    "section": "",
    "text": "View raw material in full screen.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "reproducibility/prcc.html",
    "href": "reproducibility/prcc.html",
    "title": "Sensitivity analyses",
    "section": "",
    "text": "The list of packages required for reproducing the analyses on this script are listed in Listing 1:\nListing 1: Packages required for computing sensitivity analyses.\n\n\n\nCode\n# remotes::install_github(\"jpahle/CoRC\")\nlibrary(CoRC)\n\n# tidyverse packages\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# to generate the simulations \nlibrary(lhs) # Latin Hypercube sampling\nlibrary(parallel) # parallel computing\nlibrary(ppcor) # Compute partial correlations\n\n# Table reporting\nlibrary(flextable)",
    "crumbs": [
      "PRCC"
    ]
  },
  {
    "objectID": "reproducibility/prcc.html#evaluate-the-sensitivity-of-immune-cells-to-parameter-constants",
    "href": "reproducibility/prcc.html#evaluate-the-sensitivity-of-immune-cells-to-parameter-constants",
    "title": "Sensitivity analyses",
    "section": "1 Evaluate the sensitivity of immune cells to parameter constants",
    "text": "1 Evaluate the sensitivity of immune cells to parameter constants\n\n1.1 Generate the distributions of nine critical parameters\nWe begin to extract the original constants of the 9 parameters assumed to have the strongest impact on the populations of T cell subsets, using CoRC::getParameters, reported in Table 1:\n\n\nCode\n## Retrieve parameters we want to evaluate the versatility ----\nhealthy_model &lt;- loadModel(\"../../models/team_2016_final_model_lo2016_2025_05_13.cps\")\n# S2 to be changed\nparameters_healthy &lt;- getParameters(model = healthy_model,\n                                  key = c(\"(Diff of M0 to M1).delta_m_cit\",\n                                          \"(Diff of M1 to M2).sigma\",\n                                          \"(Induction of T1 from M).s12\",\n                                          \"(Proliferation of T1).s2\",\n                                          \"(Induction of T2).s4\",\n                                          \"(Induction of T17).s21\",\n                                          \"(Induction of T17).s6\",\n                                          \"(Induction of Tr).sb\",\n                                          \"(Induction of Tr).s10\")) |&gt; \n  dplyr::select(-mapping)\n\nflextable(parameters_healthy) |&gt; \n  add_footer_row(values = \"key is direct ID of the parameter in the model, reaction describes the biological mechanism associated with the value of the parameter, and value returns the constant value assumed for healthy individuals.\", \n                 colwidths = 4) |&gt; \n  bold(part = \"header\") \n\n\n\n\n\nkeynamereactionvalue(Diff of M0 to M1).delta_m_citdelta_m_citDiff of M0 to M12.40(Diff of M1 to M2).sigmasigmaDiff of M1 to M224.00(Induction of T1 from M).s12s12Induction of T1 from M10.93(Proliferation of T1).s2s2Proliferation of T11.23(Induction of T2).s4s4Induction of T21.94(Induction of T17).s21s21Induction of T17156.17(Induction of T17).s6s6Induction of T17156.17(Induction of Tr).sbsbInduction of Tr14.02(Induction of Tr).s10s10Induction of Tr14.02key is direct ID of the parameter in the model, reaction describes the biological mechanism associated with the value of the parameter, and value returns the constant value assumed for healthy individuals.\n\n\n\nTable 1: The 9 reaction parameters evaluated for sensitivity analyses.\n\n\n\n\nIn Lo et al. (2016), they chose to perform Latin Hypercube Sampling (LHS) against Standard Random Sampling. The differences between these two randomisation approaches are further detailed in Tip 1, but briefly, the major advantage of LHS lies in its better coverage of the whole parameter sampling space, especially with a low number of observations (which is usually the case in bootstrap simulations due to their high computing cost).\n\n\n\n\n\n\nTip 1: Standard versus Latin Hypercube Sampling (LHS)\n\n\n\n\n\nRandom sampling and Latin Hypercube Sampling differ in how they distribute the sample points within the parameter space:\n\nRandom Sampling for a \\(d-\\) random vector in :\n\\[\nx_i^{(j)} \\sim \\mathcal{U}\\left(x_{\\min_j}^{(j)}, x_{\\max_j}^{(j)}\\right), \\quad j = 1, 2, \\dots, d, \\quad i = 1, 2, \\dots, N\n\\tag{1}\\]\nwhere \\(x_i^{(j)}\\) is the \\(i\\)-th sample drawn for the \\(j\\)-th dimension, \\(d=9\\) (number of parameters evaluated for sensitivity), \\(N=5000\\) the total number of parameter distributions simulated, and \\(p_j\\) the probability distribution1. Since each sample is drawn completely at random, it’s quite likely that some regions might be over-sampled while others may have gaps, with a low number of observations drawn (good coverage of the whole sampling space is only guaranteed asymptotically).\n\nIn Latin Hypercube Sampling (LHS), the sampling space is first stratified into \\(N\\) equally probable intervals for each variable \\(x^{(j)}\\); an independent permutation is subsequently applied across dimensions to avoid correlation. Finally, each sample is drawn from of the \\(N-\\) defined intervals. LHS then guarantees a more evenly distributed coverage.\n\nTo conclude, LHS provides a better Coverage of the Input Space(notably reduces the probability of clustering or missing critical regions), Improved Convergence and Efficiency by achieving a more accurate representation of the underlying distribution and leading to lower variance in estimated statistics with fewer number of available observations (see Figure 1 for further illustration). Yet, only standard random sampling is completely independent and unbiased.\n\n\n\n\n\n\nFigure 1: Randomly sampled variables vs. Latin hypercube samples, from Rustell (n.d.). With a low number of observations, the clustering pattern inherent to standard random sampling is clearly showcased.\n\n\n\n\n\n\nThe code snippet below generates the \\(N=5000\\) bootstrap distribution of the 9 evaluated parameters for robustness, using Latin Hypercube Sampling. LHS indeed guarantees better coverage of the sampling space.2.\n\n\nCode\nn_samples &lt;- 5000\n# Lower and upper bounds are computed within a ±20% range centered around the assumed parameter constant.\nparameters_sensitivity &lt;- parameters_healthy$value\nparam_ranges &lt;- tibble::tibble(parameters_name = parameters_healthy$key, \n                               LB= parameters_sensitivity *0.8,\n                               UB = parameters_sensitivity *1.2)\nset.seed(20) \nbootstrap_parameters &lt;- randomLHS(n_samples, length(parameters_sensitivity))\n\nfor (i in seq_along(parameters_sensitivity)) {\n  bootstrap_parameters[,i] &lt;- qunif(bootstrap_parameters[,i], \n                                    param_ranges$LB[i],\n                                    param_ranges$UB[i])\n}\ncolnames(bootstrap_parameters) &lt;- parameters_healthy$name\napply(bootstrap_parameters,2, quantile)\n##       delta_m_cit    sigma       s12        s2       s4      s21       s6\n##  0%      1.920171 19.20104  8.744071 0.9840326 1.552041 124.9461 124.9454\n##  25%     2.160095 21.59964  9.837180 1.1070501 1.745990 140.5559 140.5551\n##  50%     2.399952 24.00043 10.930092 1.2299544 1.939971 156.1739 156.1738\n##  75%     2.639956 26.39955 12.022974 1.3529785 2.133962 171.7861 171.7831\n##  100%    2.879926 28.79855 13.115638 1.4759205 2.327949 187.3917 187.4018\n##             sb      s10\n##  0%   11.21699 11.21689\n##  25%  12.61806 12.61786\n##  50%  14.01999 14.01992\n##  75%  15.42221 15.42153\n##  100% 16.82292 16.82372\n\n\n1n_samples &lt;- 5000\n\nparameters_sensitivity &lt;- parameters_healthy$value\n2param_ranges &lt;- tibble::tibble(parameters_name = parameters_healthy$key,\n                               LB= parameters_sensitivity *0.8,\n                               UB = parameters_sensitivity *1.2)\n\n\n3set.seed(20)\n4bootstrap_parameters &lt;- randomLHS(n_samples, length(parameters_sensitivity))\n\n# \n5for (i in seq_along(parameters_sensitivity)) {\n  bootstrap_parameters[,i] &lt;- qunif(bootstrap_parameters[,i],\n                                    param_ranges$LB[i],\n                                    param_ranges$UB[i])\n}\ncolnames(bootstrap_parameters) &lt;- parameters_healthy$name\n6apply(bootstrap_parameters,2, quantile)\n\n1\n\nDetermine the number of observations, equivalently the number of generated bootstrap distributions (here, \\(N=5000\\)).\n\n2\n\nLower and upper bounds are computed within a \\(\\pm 20\\%\\) range, centred around the parameter constant.\n\n3\n\nWe fix the random seed to ensure reproducibility of the sensitivity analyses.\n\n4\n\nThe core function of the lhs package, lhs::randomLHS(), is only able to perform standard uniform sampling. Two parameters must be provided: the number of observations to derive (here, 5000), and the dimension of the random vector (here, \\(9\\) parameters are considered).\n\n5\n\nHow to generate the uniform distribution for a given parameter \\(X_j \\sim \\mathcal{U}(0.8 \\times X_j^0, 1.2 \\times  X_j^0)\\), with \\(X_j^0\\) the constant value estimated in a healthy individual, from the standard uniform distribution \\(U \\sim \\mathcal{U}(0, 1)\\)3. By applying the Inverse Transform Sampling Theorem (see Tip 2), which implies applying the reciprocal of the CDF, in other words, the quantile function which is given in R by the stats::qunif function. Alternatively, we could have reproduced this result by applying the following affine transformation: bootstrap_parameters[,i] * (param_ranges$UB[i] -param_ranges$LB[i]) +  param_ranges$LB[i] on the observations simulated with a standard uniform.\n\n6\n\nBy applying the quantile function, and since the distribution is supposed evenly distributed on the sampling space, we expect the quantiles to be rather close from their theoretical values (for example, both the median and the mean should be close to the real constant parameter values).\n\n\n\n\n\n\n\n\nTip 2: The Inverse Transform Sampling Theorem\n\n\n\n\n\nThe Inverse Transform Sampling Theorem allows generating any probability distribution from the standard uniform distribution, \\(U \\sim \\mathcal{U}(0,1)\\). Let \\(X\\) be a continuous random variable with cumulative distribution function (CDF) \\(F(x)\\) and \\(F^{-1}\\) its reciprocal (the quantile function), then:\n\\[\nX = F^{-1}(U)\n\\]\nfollows the same distribution as \\(X\\).\n\nIn particular, for a uniform distribution \\(X \\sim \\mathcal{U}(a, b)\\), \\(a\\) and \\(b\\) being respectively the lower and upper bounds, whose CDF is given by: \\(F(x) = \\frac{x - a}{b - a}, \\quad a \\leq x \\leq b\\), then the quantile function is given by \\(F^{-1}(u) = a + u(b - a)\\).\nIn other terms, if \\(U\\) follows the standard uniform distribution, then, by applying the affine transformation \\(X=a + (b - a) U\\), \\(X\\) will follow the \\(X \\sim \\mathcal{U}(a,b)\\) distribution.\nGenerally speaking, the Inverse Transform Sampling allows generating any probability distribution from a uniform \\([0,1]\\) applying this formula: \\(X = F^{-1}(U)\\).\n\n\n\nbootstrap_parameters is a 5000 simulations times 9 parameters matrix storing all sampled parameter configurations. We displayed below only the first six lines of the simulated parameter distributions:\n\n##       delta_m_cit    sigma       s12       s2       s4      s21       s6\n##  [1,]    1.959796 23.44807  9.274411 1.439972 2.220298 136.2398 149.3445\n##  [2,]    2.066597 19.27373  9.286449 1.204420 1.758831 127.5816 155.7143\n##  [3,]    2.436843 19.47846 12.596935 1.279335 2.209452 129.4354 159.1146\n##  [4,]    2.198476 22.11835 11.983510 1.453826 1.714273 144.2711 162.5585\n##  [5,]    2.138463 25.98209  9.325547 1.168549 2.253209 158.9362 172.0287\n##  [6,]    2.118051 22.26837  9.969860 1.435285 1.571099 126.8765 153.0293\n##             sb      s10\n##  [1,] 13.45400 15.11477\n##  [2,] 16.35203 13.94127\n##  [3,] 13.20491 14.63351\n##  [4,] 12.43537 14.92586\n##  [5,] 13.86563 15.75312\n##  [6,] 13.35385 11.89732\n\n\n\n1.2 Compute steady states for the 5000 simulated parameter variations\nWe compute the corresponding steady-states for each of the \\(N=5000\\) simulated parameter configurations. This task is computationally-intensive, but can be easily parallelised, since all bootstrap samples have been generated independently. We use to that end the standard parallel package.\n1cl &lt;- makeCluster(detectCores())\n2clusterExport(cl, varlist = c(\"parameters_healthy\", \"bootstrap_parameters\"))\ncluster_environments &lt;- clusterEvalQ(cl, {\n  library(CoRC)\n  library(dplyr, quietly = TRUE)\n  healthy_model &lt;- loadModel(\"./models/team_2016_final_model_lo2016.cps\")\n})\n3sensitivity_outputs &lt;- parLapply(cl = cl,\n                    X = 1:n_samples,\n                    f = function (i) {\n5                      sensitivity_model &lt;- healthy_model |&gt; saveModelToString() |&gt;  loadModelFromString()\n                      setParameters(model = sensitivity_model,\n                                    key = parameters_healthy$key,\n                                    value = bootstrap_parameters[i,])\n                      sensitivity_model_steady_state &lt;- runSteadyState(\n                        model = sensitivity_model\n                      )$species\n                      \n                      SS_concentrations &lt;- setNames(sensitivity_model_steady_state$concentration,\n                                                    sensitivity_model_steady_state$name) |&gt;\n                        as.list() |&gt; as.data.frame() |&gt;\n                        dplyr::bind_cols(bootstrap_parameters[i, ,drop=FALSE] |&gt;\n                                           as.data.frame())\n                      return(SS_concentrations)\n                    }\n4                    , chunk.size = 50) |&gt;\n6                    dplyr::bind_rows()\n\n7stopCluster(cl)\n\n1\n\nUse detectCores() to determine the number of available CPU cores; conditionned to that number (usually 8 or 16 on recent personal laptop configurations); use makeCluster() to create the corresponding cluster4.\n\n2\n\nUse clusterExport() to send current session variables to workers, and clusterEvalQ() to load required libraries and/or execute code prior to the parallelised computations. Both functions ensure that the cluster environement has the required modules to start the computation.\n\n3\n\nThe Parallel Processing parLapply() is the counterpart of the sequential lapply() function. The first argument cl is the cluster definition. For each parameter configuration among the \\(N=5000\\), we modifify the original ODE model to reflect the LHS parameter configuration, then, compute the modified steady-states associated with that change of parameter configuration. Finally, we return for each parameter configuration a dataset with the modified 15 steady-state concentrations and the corresponding 9 parameter configurations.\n\n4\n\nThe chunk.size option controls how data is divided among workers Once computed, another batch of 50 parameter configurations is processed).\n\n5\n\nThis line is required, as CoRC uses copy by reference rather than by value. If we had just assigned the loaded healthy ODE model to the modified sensitivity model, sensitivity_model &lt;- healthy_model, every modification on sensitivity_model would also be reported on healthy_model5.\n\n6\n\nThe output of parLapply is a list of data.frame, function dplyr::bind_rows() concatenates them in a single large dataset.\n\n7\n\nStop the cluster using stopCluster() to free computational resources when no longer need.\n\n\n\n\n1.3 Compute partial correlation scores\nTo compute the correlations between variations of the constant parameters, and the concentrations of the species at steady state, Lo et al. (2016) chose to apply a rank-transformation first, which guarantees increased robustness to outliers, and reduces scaling issues associated with significant variations of orders of magnitude between the parameters.\n\n\nCode\n# reshape and rank-transform sensitivity outputs\nsensitivity_outputs &lt;- readr::read_csv(\"../../results/sensitivity_outputs.csv\") |&gt;\n  dplyr::mutate(across(where(is.numeric), rank)) \n\n\nThen, instead on relying on standard Pearson correlation which may yield spurious relationships between outcomes and parameter variations, Lo et al. (2016) computes the Partial Correlation score between the rank-transformed variations of species of interest, and the simulated parameter distributions (see Important 1 for details).\nThe pcor::ppcor function returns both:\n\nestimate, the symmetric matrix of the partial correlation coefficient between two variables (included between -1 and 1, the sign providing the type of correlation, and the absolute value the magnitude or strength of the direct relationship)\np.value, a matrix of the \\(p-\\) values for each of the tests.\nAs in Lo et al. (2016), the threshold for significance was set to \\(0.01\\).\n\nThe resulting PRCC scores between T1 and T2 immune subpopulations with the 9 parameters tested for sensitivity are reported in Table 2:\n\n\nCode\nprcc_sensitivity &lt;- pcor(sensitivity_outputs)\nprcc_estimate &lt;- prcc_sensitivity$estimate |&gt; \n  tibble::as_tibble(mat, rownames = \"species\") |&gt; \n  dplyr::select (species, T1, T2) |&gt; \n  filter(!species %in% c(\"T1\", \"T2\")) |&gt; \n  # Join on the same dataset pvalues and PRCC estimations.\n  inner_join(prcc_sensitivity$p.value |&gt; \n               tibble::as_tibble(mat, rownames = \"species\") |&gt; \n               dplyr::select (species, T1, T2) |&gt; \n               filter(!species %in% c(\"T1\", \"T2\")), by = \"species\",\n             suffix = c(\"\", \".pval\")) |&gt; \n  mutate(T1 = if_else(T1.pval &lt;=0.01, sprintf(\"%.3f*\", T1), sprintf(\"%.3f\", T1)),\n         T2 = if_else(T2.pval &lt;=0.01, sprintf(\"%.3f*\", T2), sprintf(\"%.3f\", T2))) |&gt; \n  dplyr::select(-T1.pval, -T2.pval)\n\n### Format PRCC table\nflextable(prcc_estimate) |&gt; \n  add_footer_row(values = \"* denotes significant PRCC with p-value below 0.01.\", \n                 colwidths = 3) |&gt; \n  compose(j = \"species\",\n          value = as_paragraph(as_equation(c(\"\\\\sigma_{M_{\\\\alpha}}\", \"\\\\sigma_{M_{10}}\",\n                                             \"\\\\sigma_{12}\", \"\\\\sigma_{2}\", \"\\\\sigma_{4}\",\n                                             \"\\\\sigma_{21}\", \"\\\\sigma_{6}\", \n                                             \"\\\\sigma_{\\\\beta}\", \"\\\\sigma_{10}\")))) |&gt; \n  set_header_labels(values = list(\n    species = \"\", T1 = \"PRCC for T1\", T2 = \"PRCC for T2\")) |&gt; \n  align(align = \"center\", part = \"all\") |&gt; \n  set_caption(\"Table 5: PRCC values for key parameters playing on T1 and T2 variations.\") \n\n\n\n\n\nPRCC for T1PRCC for T2NA0.918*0.364*NA-0.351*0.429*NA0.967*0.051*NA0.876*0.024NA-0.067*0.920*NA-0.0070.019NA0.021-0.007NA-0.132*0.084*NA-0.062*0.087** denotes significant PRCC with p-value below 0.01.\n\n\n\nTable 2: PRCC values of the 9 parameters benchmarked for robustness against steady-state concentrations of \\(T_1\\) and \\(T_2\\) immune cell subtypes. Reproduction of Table 5 in Lo et al. (2016).\n\n\n\n\n\n\n\n\n\n\nImportant 1: Pearson Correlation and Partial Correlation\n\n\n\n\n\nThe standard Pearson correlation coefficient between two variables \\(X\\) and \\(Y\\) is given by Equation 2:\n\\[\n\\rho_{X,Y} = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\n\\tag{2}\\]\nwhere:\n- \\(\\text{Cov}(X, Y) = \\mathbb{E}[(X - \\mu_X)(Y - \\mu_Y)]\\) is the covariance.\n- \\(\\sigma_X = \\sqrt{\\text{Var}(X)}\\) and \\(\\sigma_Y = \\sqrt{\\text{Var}(Y)}\\) are the variable standard deviations.\nIt measures the linear relationship between \\(X\\) and \\(Y\\), but does not control the effect of potential colliders or confounding variables.\n\nOn the other hand, the Partial Correlation measures the relationship between two variables while controlling for the effect of a the remaining set of variables. In a multi-dimensional framework, it’s given by Equation 3:\n\\[\n\\rho_{X,Y \\mid \\mathbf{Z}} = -\\frac{\\Omega_{X,Y}}{\\sqrt{\\Omega_{X,X} \\Omega_{Y,Y}}}\n\\tag{3}\\]\nwhere \\(\\mathbf{\\Omega} = \\mathbf{\\Sigma}^{-1}\\) is the precision matrix (inverse of the covariance matrix).\n\nCompared to standard correlations, it removes indirect Relationships triggered by another set of confusing variables \\(\\mathbf{Z}\\), thus isolates the direct relationship between \\(X\\) and \\(Y\\), and enables more straightforward interpretation by revealing truly causal relationships. For example, in Figure 2, using simply the Pearson correlation, we would have certainly observed a significant correlation between variables \\(A\\) and \\(C\\). On the other hand, with partial correlation, the spurious connection between \\(A\\) and \\(C\\) due to the confusing effect of \\(B\\) would certainly has been faded out.\n\n\nCode\ndigraph G {\n    layout=neato\n    A -&gt; B;\n    B -&gt; C;\n}\n\n\n\n\n\n\n\n\nG\n\n\n\nA\n\nA\n\n\n\nB\n\nB\n\n\n\nA-&gt;B\n\n\n\n\n\nC\n\nC\n\n\n\nB-&gt;C\n\n\n\n\n\n\n\n\nFigure 2: Simple example of chain rule associations.\n\n\n\n\n\n\n\n\n\n\n1.4 Plot rank-transformed datasets\n\n\nCode\nsensitivity_outputs_formatted &lt;- sensitivity_outputs |&gt;\n  # tidy format: one column storing PRCC values for the x-axis, one for the y-axis, and another for the facets\n  dplyr::select (c(\"T1\", \"T2\", \"sb\", \"s10\", \"s12\")) |&gt; \n  tidyr::pivot_longer(cols = c(\"sb\", \"s10\", \"s12\"), names_to = \"parameters\", values_to = \"x\") |&gt;\n  tidyr::pivot_longer(cols = c(\"T1\", \"T2\"), names_to = \"species\", values_to = \"y\") |&gt; \n  # provide the same order of facets for direct comparison\n  dplyr::mutate(parameters = factor(parameters, \n                                    levels = c(\"sb\", \"s10\", \"s12\"),\n                                    labels = c(\"sigma[b]\", \"sigma[10]\", \"sigma[12]\"),\n                                    ordered = TRUE),\n                species = factor(species, \n                                 levels = c(\"T1\", \"T2\"),\n                                 labels = c(\"T[1]\",\"T[2]\")))\n\n# Subtitles customised for each facet, including the p-value.\nprcc_values &lt;- prcc_sensitivity$estimate\nprcc_sensitivity_annot &lt;- data.frame(x=n_samples/2, y=Inf, \n                                     lab=factor(paste(\"PRCC =\", c(prcc_values[\"T1\", \"sb\"],\n                                                           prcc_values[\"T1\", \"s10\"],\n                                                           prcc_values[\"T1\", \"s12\"],\n                                                           prcc_values[\"T2\", \"sb\"],\n                                                           prcc_values[\"T2\", \"s10\"],\n                                                           prcc_values[\"T2\", \"s12\"]) |&gt; \n                                                 sprintf(fmt = '%.3f')), ordered = TRUE), \n                                     parameters=factor(rep(c(\"sigma[b]\", \"sigma[10]\", \"sigma[12]\"), 2), \n                                                       ordered = TRUE),\n                                     species= factor(c(rep(\"T[1]\", 3), rep(\"T[2]\", 3)), \n                                                     ordered = TRUE))\n\n\nWe generate a scatter plot after applying rank-transformation of \\(T_1\\) and \\(T_2\\) immune cells subsets, against 3 parameters playing a critical role on the viability of cell pools, namely \\(\\sigma_b\\), \\(\\sigma_{10}\\) and \\(\\sigma_{12}\\), the first two controlling the activation rate of Tregs, and the induction of \\(T_1\\) by the global pool of macrophages (including both \\(M1\\) and \\(M2\\) types)6.\n\n\nCode\nSS_plots &lt;- ggplot(sensitivity_outputs_formatted, aes(y = y, x=x)) +\n  geom_point(size = 0.1, col = \"blue\", shape = 20) +\n  # The labeller trick enables to use Latex notations for the subtitles of facets.\n  facet_grid(species ~ parameters, \n             labeller = labeller(.rows = label_parsed, .cols = label_parsed)) +\n  geom_label(aes(x, y, label=lab),\n            data=prcc_sensitivity_annot, vjust=0.8, size = 3) +\n  xlab(\"Cell Species\") + ylab(\"Free and Variable Parameters\") +\n  # Guarantees minimal plot background that would hinder visibility of the output.\n  theme_minimal() +\n  theme(panel.grid.major = element_blank(), \n        panel.grid.minor = element_blank(),\n        strip.text.y = element_text(angle = 0)) \nSS_plots\n\n\n\n\n\n\n\n\nFigure 3: Scatter plots of rank-transformed \\(T_1\\) and \\(T_2\\) against 3 parameters enumerated in Table 2, exhbiting both strong partial correlation (\\(|\\text{PRCC}|&gt;0.5\\) and \\(p-\\)value \\(&lt;0.01\\)). Reproduction of (Lo et al. 2016, 11), Fig.2.\n\n\n\n\n\nOne of the major advantages of the ggplot2 package lies in its seamless ability to save the graphical object in a variety of formats, including pdf and png, as illustrated in Listing 2:\n\n\n\n\nListing 2: Code snippet not run, used for illustration example.\n\n\n\nCode\n# output is pdf, with a high resolution close to retina visual discrimination ability\nggsave(filename = \"../../results/Fig2_PRCC.pdf\", \n       plot = SS_plots, dpi = 600, width = 20, height = 10,\n       units = \"cm\")",
    "crumbs": [
      "PRCC"
    ]
  },
  {
    "objectID": "reproducibility/prcc.html#footnotes",
    "href": "reproducibility/prcc.html#footnotes",
    "title": "Sensitivity analyses",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOnly the uniform sampling, \\(U_j \\sim \\mathcal{U}(0,1)\\), is provided with the LHSpackage. We detailed in Tip 2 how to simulate any kind of probability distribution from the standard uniform distribution.↩︎\nNote however that both standard random sampling and LHS assume independence between the parameters values, a strong and quite unlikely biological premise.↩︎\nNote that we assume independence between the parameters, and that the quantile call is performed independently for each of the dimensions.↩︎\nWith 8 cores, for instance, 8 computations can be performed in parallel. It might be advised to free completely a CPU to avoid computer freezing↩︎\nAnother way to visualise the copy by reference approach: simply copy the ODE model in another variable healthy_model_copy &lt;- healthy_model in the R canonical way. Compare the storage addresses: lobstr::obj_addr(healthy_model) and lobstr::obj_addr(healthy_model_copy); you will note that they are identical↩︎\nNote that we don’t round the PRCC values, but only format them to display 3 significant digits using the native C sprintf(): difference between both approaches is notably crucial when saving datasets to avoid loss of numerical precision↩︎",
    "crumbs": [
      "PRCC"
    ]
  }
]